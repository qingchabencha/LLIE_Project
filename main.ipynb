{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16mB2oIHoeuv",
        "outputId": "9c534c59-8553-4b60-f5cb-49c1a1eb6d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/LLIE_Project\n",
            "/content/gdrive/My Drive/LLIE_Project\n"
          ]
        }
      ],
      "source": [
        "# For Google Colaboratory\n",
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    # mount google drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    path_to_file = '/content/gdrive/My Drive/LLIE_Project'\n",
        "    print(path_to_file)\n",
        "    # change current path to the folder containing \"file_name\"\n",
        "    os.chdir(path_to_file)\n",
        "    !pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from DatasetAndAugmentation.LowHighDataAugment import PairedTransforms\n",
        "from DatasetAndAugmentation.LowHightDataset import LOLPairedDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from model.model import RELLIE\n",
        "\n",
        "try:\n",
        "  from piqa import SSIM\n",
        "except:\n",
        "  !pip install piqa\n",
        "  from piqa import SSIM\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW, Adam"
      ],
      "metadata": {
        "id": "53FNpsPtohAs",
        "outputId": "cc96708f-f49f-4e9f-bbb6-facf7cb33750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting piqa\n",
            "  Downloading piqa-1.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from piqa) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from piqa) (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->piqa) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->piqa) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->piqa) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->piqa) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->piqa) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->piqa) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->piqa) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.12.0->piqa)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->piqa) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->piqa) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.0->piqa) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.13.0->piqa) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.13.0->piqa) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.0->piqa) (3.0.2)\n",
            "Downloading piqa-1.3.2-py3-none-any.whl (32 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, piqa\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 piqa-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yexuz9D7ozns",
        "outputId": "c1d43170-554a-48c9-dc5e-b23c5eb7c73e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxwf05LIoeuw"
      },
      "source": [
        "# Define the dir of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GV4zTT2foeuw"
      },
      "outputs": [],
      "source": [
        "# direction of the dataset\n",
        "dataset_dir = \"/path/to/dataset\"\n",
        "# directory of low-light images\n",
        "train_low_dir = \"./LOLdataset/train/low\"\n",
        "# directory of high-light images\n",
        "train_bright_dir = \"./LOLdataset/train/high\"\n",
        "\n",
        "# test\n",
        "test_low_dir = \"./LOLdataset/test/low\"\n",
        "test_bright_dir = \"./LOLdataset/test/high\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrqON-33oeuw"
      },
      "source": [
        "# create the train/test pic transformer, dataset and dataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KebZVwMUoeux"
      },
      "outputs": [],
      "source": [
        "# create transform class to transform the image into tensor\n",
        "train_batch_size = 1\n",
        "train_transform = PairedTransforms(image_size=(400, 600), train=True)\n",
        "train_dataset = LOLPairedDataset(train_low_dir, train_bright_dir, transform=train_transform, train=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "test_transform = PairedTransforms(image_size=(400, 600), train=False)\n",
        "test_dataset = LOLPairedDataset(test_low_dir, test_bright_dir, transform=train_transform, train=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbDki-NLoeux"
      },
      "source": [
        "# Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WBH352ACoeux"
      },
      "outputs": [],
      "source": [
        "model = RELLIE().to(device)\n",
        "lr = 0.0001\n",
        "optimizer = Adam(\n",
        "    model.parameters(), lr=lr\n",
        ")\n",
        "\n",
        "class SSIMLoss(SSIM):\n",
        "    def forward(self, x, y):\n",
        "        return 1. - super().forward(x, y)\n",
        "\n",
        "mse_loss = nn.MSELoss()\n",
        "ssim_loss = SSIMLoss().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJdzucF1oeux"
      },
      "source": [
        "# Pipline of training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Mo32Ul8zoeuy"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, optimizer, epoch = 0):\n",
        "    running_total = 0\n",
        "    running_ref = 0\n",
        "    running_dec = 0\n",
        "    running_ill = 0\n",
        "    num_batches = 0\n",
        "    for batch in train_loader:\n",
        "        input_low_light = batch[\"low\"].to(device)\n",
        "        target_high_light = batch[\"bright\"].to(device)\n",
        "        # forward\n",
        "        reflectance_low_light,\\\n",
        "            reflectance_high_light,\\\n",
        "                illumination_low_light,\\\n",
        "                    illumination_high_light,\\\n",
        "                        enhanced_illumination = model(input_low_light, target_high_light, 'train')\n",
        "\n",
        "        # calculate loss\n",
        "        decomposition_loss = ssim_loss(reflectance_high_light * illumination_high_light, target_high_light) + \\\n",
        "            ssim_loss(reflectance_low_light * illumination_low_light, input_low_light)\n",
        "        reflectance_loss = mse_loss(reflectance_low_light, reflectance_high_light)\n",
        "        illumination_enhance_loss = ssim_loss(enhanced_illumination * reflectance_low_light, target_high_light)\n",
        "\n",
        "        total_loss = 1.5 * decomposition_loss + 0.75 * reflectance_loss + 2.0 * illumination_enhance_loss\n",
        "\n",
        "        running_dec += decomposition_loss.detach().item()\n",
        "        running_ref += reflectance_loss.detach().item()\n",
        "        running_ill += illumination_enhance_loss.detach().item()\n",
        "        running_total += total_loss.detach().item()\n",
        "\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        num_batches += 1\n",
        "\n",
        "    print(f'Epoch {epoch + 1}:\\t Total Loss = {running_total / num_batches}\\t d_loss = {running_dec / num_batches}\\t r_loss = {running_ref / num_batches}\\t i_loss = {running_ill/num_batches}')\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    running_total = 0\n",
        "    num_batches = 0\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "          input_low_light = batch[\"low\"].to(device)\n",
        "          target_high_light = batch[\"bright\"].to(device)\n",
        "\n",
        "          # forward\n",
        "          predict_high_light = model(input_low_light, None, 'eval')\n",
        "\n",
        "          loss = ssim_loss(predict_high_light, target_high_light)\n",
        "          running_total += loss.item()\n",
        "          num_batches += 1\n",
        "\n",
        "    print(f\"Evaluation on test set: Loss = {running_total / num_batches}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBqtckZkoeuy"
      },
      "outputs": [],
      "source": [
        "model_dict_folder = \"./model_files\"\n",
        "if not os.path.exists(model_dict_folder):\n",
        "    os.makedirs(model_dict_folder)\n",
        "\n",
        "starting_epoch = 0\n",
        "load_model = False\n",
        "\n",
        "if load_model:\n",
        "  model.load_state_dict(torch.load(f'epoch_{starting_epoch}_state.pt'), weights_only=True)\n",
        "\n",
        "for epoch in range(starting_epoch, 200):\n",
        "    if epoch % 20 == 1:\n",
        "      lr = lr / 2\n",
        "      optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_one_epoch(model, train_loader, optimizer, epoch)\n",
        "    torch.save(model.state_dict(), os.path.join(model_dict_folder, f'epoch_{epoch}_state.pt'))\n",
        "    evaluate(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhDoIvMaoeuy"
      },
      "source": [
        "# Visualize the output of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZnD21Weoeuy"
      },
      "outputs": [],
      "source": [
        "num_images_show = 5\n",
        "fig, axes = plt.subplots(3, num_images_show, figsize=(3 * train_batch_size, 9))\n",
        "for i in range(num_images_show):\n",
        "    batch = next(iter(test_loader))\n",
        "    input_low_light = batch[\"low\"].to(device)\n",
        "    #print(input_low_light)\n",
        "    target_high_light = batch[\"bright\"].squeeze(0).to(device)\n",
        "\n",
        "    #print(target_high_light)\n",
        "    with torch.no_grad():\n",
        "      predict_high_light = model(input_low_light, None, 'eval').squeeze(0)\n",
        "\n",
        "\n",
        "    predict_high_light_PIL, target_high_light_PIL = train_transform.tensor2PIL(predict_high_light, target_high_light)\n",
        "    input_low_light_PIL, _  = train_transform.tensor2PIL(input_low_light.squeeze(0), None)\n",
        "\n",
        "    # 第1行: Picture input into the model\n",
        "    axes[0, i].imshow(input_low_light_PIL)\n",
        "    axes[0, i].set_title(f\"Input {i+1}\")\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "    # 第2行: Picture output from the model, augmented by the model\n",
        "    axes[1, i].imshow(predict_high_light_PIL)\n",
        "    axes[1, i].set_title(f\"Predicted {i+1}\")\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "    # 第3行：The target picture\n",
        "    axes[2, i].imshow(target_high_light_PIL)\n",
        "    axes[2, i].set_title(f\"Target {i+1}\")\n",
        "    axes[2, i].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxkf1v8yxRgU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}